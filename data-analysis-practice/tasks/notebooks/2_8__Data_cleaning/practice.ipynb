{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Some of the cells below contain the magic command `%%writefile`, which saves the contents of a cell into a specified file. In the notebook provided, all such commands are commented. Please make sure to follow the steps below after you have completed the subtasks:\n",
    "\n",
    "1. Uncomment **all** `%%writefile` commands\n",
    "2. Rerun the entire notebook\n",
    "\n",
    "This is important because, as we will check the `.py` files generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Missing value analysis\n",
    "\n",
    "Your task is to implement a function that analyzes missing values in a given dataframe and imputes missing values if necessary. Please use the template `handle_missing_values` for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./../solutions/missing.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def handle_missing_values(\n",
    "    df: pd.DataFrame, \n",
    "    percent_missing_per_row: float = 0.5,\n",
    "    percent_missing_per_column: float = 0.5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Handles missing values in a given dataframe according to the instructions below.\n",
    "\n",
    "    Instructions for handling missing values (the steps below should be executed sequentially, one by one):\n",
    "    0) Remove rows where the percentage of missing values is greater than `percent_missing_per_row`.\n",
    "    1) Remove columns where the percentage of missing values is greater than `percent_missing_per_column`.\n",
    "    2) For each categorical column impute missing values with the string \"missing\".\n",
    "    3) For each numerical column impute missing values with the corresponding column-wise means.\n",
    "\n",
    "    NOTE: It is not allowed to change the indices in the result dataframe, meaning that the initial order of rows\n",
    "    (and the corresponding indices) should stay the same.\n",
    "    \n",
    "    HINT: You may find `.loc/.iloc` indexing useful. \n",
    "\n",
    "    Args:\n",
    "        df: pd.DataFrame, a dataframe for handling missing values.\n",
    "        percent_missing_per_row: float, the threshold for removing rows.\n",
    "        percent_missing_per_column: float, the threshold for removing columns.\n",
    "    Returns:\n",
    "        pd.DataFrame, the resulting dataframe.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # 0) Remove rows with high missing value percentage\n",
    "    df_copy = df_copy[df_copy.isnull().sum(axis=1) / df_copy.shape[1] <= percent_missing_per_row]\n",
    "    df_copy = df_copy.reset_index(drop=True) # Reset index to avoid issues\n",
    "\n",
    "    # 1) Remove columns with high missing value percentage\n",
    "    df_copy = df_copy.loc[:, df_copy.isnull().sum(axis=0) / df_copy.shape[0] <= percent_missing_per_column]\n",
    "\n",
    "    # 2) Impute missing values in categorical columns\n",
    "    for col in df_copy.select_dtypes(include='object'):\n",
    "        df_copy[col] = df_copy[col].fillna(\"missing\")\n",
    "\n",
    "    # 3) Impute missing values in numerical columns\n",
    "    for col in df_copy.select_dtypes(include='number'):\n",
    "        df_copy[col] = df_copy[col].fillna(df_copy[col].mean())\n",
    "    \n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "\n",
    "# Test 1\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    \"b\": [2, 3, 4, 5, 6, 7, 8],\n",
    "    \"c\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"],\n",
    "    \"d\": [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    handle_missing_values(df),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1, 2, 3, 4, 5, 6, 7],\n",
    "        \"b\": [2, 3, 4, 5, 6, 7, 8],\n",
    "        \"c\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"],\n",
    "        \"d\": [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"],\n",
    "    })\n",
    ")\n",
    "\n",
    "# Test 2\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [np.nan, 2, 3, 4, 5, 6, np.nan],\n",
    "    \"b\": [2, 3, 4, 5, 6, 7, np.nan],\n",
    "    \"c\": [np.nan, \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"],\n",
    "    \"d\": [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", np.nan],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    handle_missing_values(df),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [4.0, 2, 3, 4, 5, 6],\n",
    "        \"b\": [2.0, 3, 4, 5, 6, 7],\n",
    "        \"c\": [\"missing\", \"2\", \"3\", \"4\", \"5\", \"6\"],\n",
    "        \"d\": [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\"],\n",
    "    })\n",
    ")\n",
    "\n",
    "# Test 3\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1, np.nan, 3, np.nan, np.nan, 6, np.nan],\n",
    "    \"b\": [2, 3, 4, 5, 6, 7, 8],\n",
    "    \"c\": [np.nan, \"2\", np.nan, \"4\", np.nan, \"6\", \"7\"],\n",
    "    \"d\": [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    handle_missing_values(df),\n",
    "    pd.DataFrame({\n",
    "        \"b\": [2, 3, 4, 5, 6, 7, 8],\n",
    "        \"c\": [\"missing\", \"2\", \"missing\", \"4\", \"missing\", \"6\", \"7\"],\n",
    "        \"d\": [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"],\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Identifying outliers\n",
    "\n",
    "Your task is to implement a function that uses Tukey's fences to identify outliers in a given dataframe. Please use the template `identify_outliers` for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./../solutions/outliers.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def identify_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    df_copy['outliers_count'] = 0\n",
    "    for col in df_copy.select_dtypes([np.number]).columns:\n",
    "        Q1 = df_copy[col].quantile(0.25)\n",
    "        Q3 = df_copy[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_copy['outliers_count'] += ((df_copy[col] < lower_bound) | (df_copy[col] > upper_bound)).astype(int)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "\n",
    "# Test 1\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1, 2, 3, 4, 5, 6, 7, 8, 90000, 100000],\n",
    "    \"b\": [-100000, -90000, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"d\": list(map(str, range(10))),\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    identify_outliers(df),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1, 2, 3, 4, 5, 6, 7, 8, 90000, 100000],\n",
    "        \"b\": [-100000, -90000, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        \"d\": list(map(str, range(10))),\n",
    "        \"outliers_count\": [1, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
    "    })\n",
    ")\n",
    "\n",
    "# Test 2\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1, 2, 3, 4, 5, 6, 7, 8, 90000, 100000],\n",
    "    \"b\": [-100000, -90000, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"c\": [-100000, 1, 2, 3, 4, 5, 6, 7, 8, 90000],\n",
    "    \"d\": list(map(str, range(10))),\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    identify_outliers(df),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1, 2, 3, 4, 5, 6, 7, 8, 90000, 100000],\n",
    "        \"b\": [-100000, -90000, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        \"c\": [-100000, 1, 2, 3, 4, 5, 6, 7, 8, 90000],\n",
    "        \"d\": list(map(str, range(10))),\n",
    "        \"outliers_count\": [2, 1, 0, 0, 0, 0, 0, 0, 1, 2]\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Remove duplicated observations\n",
    "\n",
    "Your task is to implement a function that removes duplicated observations from a given dataframe. Please use the template `remove_duplicates` for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./../solutions/duplicates.py\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def remove_duplicates(df: pd.DataFrame, tol: float=1e-5) -> pd.DataFrame:\n",
    "    \"\"\"Removes duplicated rows from a given dataframe.\n",
    "\n",
    "    NOTE: The `tol` parameter should be used to compare values in numerical columns (|a - b| < tol => (a == b)).\n",
    "    NOTE: If a dataframe has three rows [`a`, `b`,`c`], `a == b` and `b == c` -> only `a` should be kept. \n",
    "    NOTE: Assume that `NaN == NaN` is the expected behavior.\n",
    "    NOTE: If two rows are `equal`, please keep the row with the lowest index.\n",
    "    NOTE: It is not allowed to change the order of rows in the resulting dataframe.\n",
    "    NOTE: It is not allowed to change the indices in the resulting dataframe, meaning that the initial order of rows\n",
    "    (and the corresponding indices) should stay the same.\n",
    "\n",
    "    Args:\n",
    "        df: pd.DataFrame, a dataframe for deduplication.\n",
    "        tol: float, the precision with which numerical values should be compared.\n",
    "    Returns:\n",
    "        pd.DataFrame, the resulting dataframe after deduplication.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convert numerical columns to object dtype for easier comparison with tolerance\n",
    "    for col in df_copy.select_dtypes(include='number'):\n",
    "        df_copy[col] = df_copy[col].round(decimals=-int(np.log10(tol)))\n",
    "\n",
    "    # No need to add index, use the implicit index for drop_duplicates\n",
    "    df_copy = df_copy.drop_duplicates(keep='first') \n",
    "    \n",
    "    # Reset the index to match original DataFrame\n",
    "    df_copy = df_copy.reset_index(drop=True)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "\n",
    "# Test 1\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1, 1, 2, 3],\n",
    "    \"b\": [1, 1, 2, 3],\n",
    "    \"c\": [\"1\", \"1\", \"2\", \"3\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1, 2, 3],\n",
    "        \"b\": [1, 2, 3],\n",
    "        \"c\": [\"1\", \"2\", \"3\"],\n",
    "    }, index=[0, 2, 3])\n",
    ")\n",
    "\n",
    "# Test 2\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [np.nan, np.nan, 2, 3],\n",
    "    \"b\": [np.nan, np.nan, 2, 3],\n",
    "    \"c\": [\"1\", \"1\", \"2\", \"3\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [np.nan, 2, 3],\n",
    "        \"b\": [np.nan, 2, 3],\n",
    "        \"c\": [\"1\", \"2\", \"3\"],\n",
    "    }, index=[0, 2, 3])\n",
    ")\n",
    "\n",
    "# Test 3\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1 + 1e-4, 1 - 1e-5, 1, 2],\n",
    "    \"b\": [2, 2 + 1e-4, 2 - 1e-5, 3],\n",
    "    \"c\": [\"1\", \"1\", \"1\", \"3\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df, tol=1e-3),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1 + 1e-4, 2],\n",
    "        \"b\": [2.0, 3.0],\n",
    "        \"c\": [\"1\", \"3\"],\n",
    "    }, index=[0, 3])\n",
    ")\n",
    "\n",
    "# Test 4\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1 + 1e-1, 1 + 1e-2 - 1e-5, 1, 2],\n",
    "    \"b\": [2 + 1e-1, 2 + 1e-2 - 1e-5, 2, 3],\n",
    "    \"c\": [\"1\", \"1\", \"1\", \"3\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df, tol=1e-2),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1 + 1e-1, 1 + 1e-2 - 1e-5, 2],\n",
    "        \"b\": [2 + 1e-1, 2 + 1e-2 - 1e-5, 3],\n",
    "        \"c\": [\"1\", \"1\", \"3\"],\n",
    "    }, index=[0, 1, 3])\n",
    ")\n",
    "\n",
    "# Test 5\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1, 1 + 1e-3 - 1e-5, 1 - 1e-3 + 1e-5, 2],\n",
    "    \"b\": [2, 2 + 1e-3 - 1e-5, 2 - 1e-3 + 1e-5, 3],\n",
    "    \"c\": [\"1\", \"1\", \"1\", \"1\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df, tol=1e-3),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1.0, 2.0],\n",
    "        \"b\": [2.0, 3.0],\n",
    "        \"c\": [\"1\", \"1\"],\n",
    "    }, index=[0, 3])\n",
    ")\n",
    "\n",
    "# Test 6\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1 + 1e-3 - 1e-5, 1, 1 - 1e-3 + 1e-5, 2],\n",
    "    \"b\": [2 + 1e-3 - 1e-5, 2, 2 - 1e-3 + 1e-5, 3],\n",
    "    \"c\": [\"1\", \"1\", \"1\", \"1\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df, tol=1e-3),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1 + 1e-3 - 1e-5, 2],\n",
    "        \"b\": [2 + 1e-3 - 1e-5, 3],\n",
    "        \"c\": [\"1\", \"1\"],\n",
    "    }, index=[0, 3])\n",
    ")\n",
    "\n",
    "# Test 7\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1e-2, 2e-2, 3e-2],\n",
    "    \"b\": [3e-2, 2e-2, 1e-2],\n",
    "    \"c\": [\"1\", \"1\", \"1\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df, tol=1e-2 + 1e-6),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1e-2],\n",
    "        \"b\": [3e-2],\n",
    "        \"c\": [\"1\"],\n",
    "    }, index=[0])\n",
    ")\n",
    "\n",
    "# Test 8\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [1e-2, 2e-2, 3e-2],\n",
    "    \"b\": [3e-2, 2e-2, 1e-2],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df, tol=1e-2 + 1e-6),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [1e-2],\n",
    "        \"b\": [3e-2],\n",
    "    }, index=[0])\n",
    ")\n",
    "\n",
    "# Test 9\n",
    "df = pd.DataFrame({\n",
    "    \"a\": [\"a\", \"b\", \"a\"],\n",
    "    \"b\": [\"a\", \"b\", \"a\"],\n",
    "})\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    remove_duplicates(df),\n",
    "    pd.DataFrame({\n",
    "        \"a\": [\"a\", \"b\"],\n",
    "        \"b\": [\"a\", \"b\"],\n",
    "    }, index=[0, 1])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

